{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f0a847",
   "metadata": {},
   "source": [
    " January 16, 2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162673ab",
   "metadata": {},
   "source": [
    "# Social Data Science Base Camp Exam \n",
    "____\n",
    "\n",
    "In this project, I will extract and analyse data on UFC fighters. While I do not have a personal affinity for the sport, I frequently view it as a result of my boyfriend's interest. During one of his sessions of research on the UFC website, I was intrigued by its design and the comprehensive statistics provided on each fighter's performance. I also observed the presence of links to their social media profiles, adding to the website's appeal.\n",
    "\n",
    "\n",
    "To meet the exam criteria and to make this notebook more organized, the structure is as follows:\n",
    "\n",
    "**The notebook is divided into five overall sections**: \n",
    "1. Scraping the UFC website from data \n",
    "2. Extracting Twitter information \n",
    "    * Conducting word counts \n",
    "3. Merging datasets \n",
    "4. Data visualization \n",
    "5. Data analysis \n",
    "    * Linear regression\n",
    "    * Linear regression with non-binary categorical variable \n",
    "    * Logistic regression \n",
    "    \n",
    "\n",
    "\n",
    "Below, I will start with the first section. \n",
    "\n",
    "## Section 1: Scraping the UFC website \n",
    "\n",
    "For this task, I will be scraping data from the official website of the Ultimate Fighting Championship (UFC). The website contains a comprehensive list of all fighters in the UFC and provides detailed information on each fighter, including performance statistics (such as wins by knockout), background information (such as age), and links to their social media pages. To narrow down the list of fighters, I have applied filters based on fighting style, selecting those who specialize in MMA, jiu-jitsu, and Brazilian jiu-jitsu. This process has yielded a total count of around 300 fighters.\n",
    "\n",
    "I began by scraping data from 336 fighters, but due to empty fields within the HTML table and/or advertisements, I removed these and ended up with a final count of 265 fighters. Using the HTML link provided by the UFC for each fighter, I extracted additional information from their profiles such as age, wins by knockout, wins by submission, significant strikes landed per minute, and arm reach. I find these variables interesting for the analysis as they might help answer questions such as the relationship between arm reach and wins by knockout, or other relationships.\n",
    "\n",
    "At the end of section 1, I compiled all of the collected data into a data frame and saved it as a CSV file for further analysis.\n",
    "\n",
    "Let's begin!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing requests and getting the HTML code\n",
    "\n",
    "import requests as rq\n",
    "ufc = rq.get('https://www.ufc.com/athletes/all?filters%5B0%5D=fighting_style%3A7146')\n",
    "\n",
    "# checking if status code 200, ensuring that everyting is fine.\n",
    "ufc.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826de046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e60d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning it into a beautiful soup object\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "ufc_soup = BeautifulSoup(ufc.text) #text is basically the html code\n",
    "ufc_soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ac1e3e",
   "metadata": {},
   "source": [
    "Upon examining the webpage, I noticed that all the fighter data is organized within a table. As such, I narrowed the scope of the data extraction process to only include the information contained within this table, which I stored in an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06744f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter = ufc_soup.find_all('li', class_ = \"l-flex__item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbcbb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take a look\n",
    "fighter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a5dfc3",
   "metadata": {},
   "source": [
    "The page I am trying to scrape has a \"load more\" button. As a result, my code from above only provided 12 fighters (as are presented on the first page on the website). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fighter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64884e3f",
   "metadata": {},
   "source": [
    "To scrape information from the other fighters, I will use the selenium package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7294b404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing selenium\n",
    "import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4dfff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing webdrive:\n",
    "\n",
    "import webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df17dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Furthermore, there are several packages I need for making this work.\n",
    "\n",
    "import webdriver_manager\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# the URL to the ufc webpage:\n",
    "UFC_URL = \"https://www.ufc.com/athletes/all?filters%5B0%5D=fighting_style%3A7145&filters%5B1%5D=fighting_style%3A7146&filters%5B2%5D=fighting_style%3A7150\"\n",
    "\n",
    "PATIENCE_TIME = 60\n",
    "\n",
    "LOAD_MORE_BUTTON_XPATH = \"//a[@class='button']\" # the xpath for the load more button. I found this \n",
    "                                                # when I inspected the element. From here, I could \n",
    "                                                # simply copy the xpath from the inspect\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install()) # This code below installs the webdriver. \n",
    "                                #I have chosen chrome for convenience purposes as this was already \n",
    "                                # installed on my computer. When running this code, it opens a new chrome window. \n",
    "driver.get(UFC_URL)\n",
    "\n",
    "# There is probably a more pythonic way of doing this, but this is how I did: \n",
    "# To reach the final page, I'd have to click the \"load more\" button 27 times:\n",
    "\n",
    "for n in range(27):\n",
    "    try:\n",
    "        loadMoreButton = driver.find_element(By.XPATH, LOAD_MORE_BUTTON_XPATH)\n",
    "        time.sleep(2)\n",
    "        loadMoreButton.click()\n",
    "        time.sleep(5) \n",
    "    except:\n",
    "        pass\n",
    "print(\"Complete\")\n",
    "time.sleep(10)\n",
    "\n",
    "\n",
    "page = driver.page_source # now I got the page in the page element\n",
    "\n",
    "soup = BeautifulSoup(page, \"html.parser\") #making the page into a soup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a833da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating it\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db6cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as above, I extract the table I want from the soup and see how many fighters we have now \n",
    "# - luckily, a bit more than 12 this time.\n",
    "\n",
    "fighter_soup = soup.find_all('li', class_ = \"l-flex__item\")\n",
    "print(len(fighter_soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f703f04d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inspecting one \n",
    "\n",
    "fighter_soup[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe658ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the name \n",
    "\n",
    "fighter_soup[1].find('span', class_='c-listing-athlete__name').text #get the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8079c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the nickname \n",
    "\n",
    "fighter_soup[1].findAll('div', class_='field__item')[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6305bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the weight class\n",
    "\n",
    "fighter_soup[1].findAll('div', class_='field__item')[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a18124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the twitter\n",
    "\n",
    "fighter_soup[1].findAll('a', class_='c-listing-athlete-flipcard__social-link')[0].get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a22382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the profile link + adding the first part of the link to the string as this is not included in the html code\n",
    "\n",
    "ufclink = \"https://www.ufc.com\"\n",
    "ufclink + str(fighter_soup[1].find('a')['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e84bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function so that I can get all the information for each fighter at once\n",
    "\n",
    "def extract_fighter_info(soup): \n",
    "\n",
    "    name = soup.find('span', class_='c-listing-athlete__name').text\n",
    "    if 'weight' in soup.find_all('div', class_='field__item')[1].text:\n",
    "        nickname = np.nan \n",
    "    else:\n",
    "        nickname = soup.find_all('div', class_='field__item')[1].text\n",
    "    \n",
    "    if ' \\n\\n\\n\\n\\n' in soup.find_all('div', class_='field__item')[2].text:\n",
    "        weight_class = soup.find_all('div', class_='field__item')[1].text\n",
    "    else: \n",
    "        weight_class = soup.find_all('div', class_='field__item')[2].text\n",
    "    \n",
    "    twitter_str = \"twitter\"\n",
    "    \n",
    "    twitter_final = []\n",
    "    \n",
    "\n",
    "    for i in [0,1,2]:\n",
    "        try:\n",
    "            link_temp0 = soup.find_all('a', class_='c-listing-athlete-flipcard__social-link')[0].get('href')\n",
    "            link_temp1 = soup.find_all('a', class_='c-listing-athlete-flipcard__social-link')[1].get('href')\n",
    "            link_temp2 = soup.find_all('a', class_='c-listing-athlete-flipcard__social-link')[2].get('href')\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if twitter_str in link_temp0: \n",
    "        twitter_final.append(link_temp0)\n",
    "    elif twitter_str in link_temp1:\n",
    "        twitter_final.append(link_temp1)\n",
    "    elif twitter_str in link_temp1: \n",
    "        twitter_final.append(link_temp2)\n",
    "    else: \n",
    "        twitter_final.append(np.nan)\n",
    "        \n",
    "        \n",
    "    profil_link = ufclink + str(soup.find('a')['href'])\n",
    "\n",
    "    return name, nickname, weight_class, twitter_final, profil_link\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184e694c",
   "metadata": {},
   "source": [
    "The function that I have written contains several loops, each of which serves a specific purpose. One of the reasons for this is that I discovered during the data extraction process that not all fighters had nicknames. As a result, the weight class information was stored in the position of the nickname (i.e., field_item[2] became field_item[1]). Consequently, when I created the data frame, some of the values for the fighters did not match the correct columns.\n",
    "\n",
    "Furthermore, the order of the Twitter links was not consistent for all fighters. To address this issue, I had to write a loop that iterated through the information within 'c-listing-athlete-flipcard__social-link', and then only extracted the info if the string contained 'twitter'. This approach ensured that the Twitter handles were properly assigned to the correct fighters in the final data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93372723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing if it works - luckily it does.\n",
    "extract_fighter_info(fighter_soup[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1409c0d7",
   "metadata": {},
   "source": [
    "Getting this information for all the fighters by iterating through the fighter_soup, using the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ae443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "info = []\n",
    "for i in range(len(fighter_soup)):\n",
    "    try:\n",
    "        temp = extract_fighter_info(fighter_soup[i])\n",
    "    except: \n",
    "        temp = pd.NA\n",
    "    info.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a943ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# everything should now be stored in \"Info\"\n",
    "\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a79597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first one is an NA which makes it difficult to execute the code below when we want \n",
    "# the list in a dataframe. I remove the first NA only. \n",
    "\n",
    "info.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double checking that all fighters still are with us\n",
    "\n",
    "len(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b66b0f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# making the info to dataframe\n",
    "\n",
    "ufc_df = pd.DataFrame(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c4154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are, however, extra whitespace and newline characters at the names. Cleaning it:\n",
    "info1 = []\n",
    "\n",
    "for inf in info: \n",
    "    try:\n",
    "        temp = inf[0].strip()\n",
    "    except TypeError: \n",
    "        temp= pd.NA\n",
    "    info1.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab5876",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(info1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df8b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the column 0 to the info1 list with cleaned names\n",
    "ufc_df[0]=info1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f350d125",
   "metadata": {},
   "source": [
    "Lets drop the rows that have all NAN values.\n",
    "The reason why some rows have all NA values is that some of the boxes of the structured HTML table contain no fighter, but instead just emty spaces or an advertisement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df82ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "ufc_df = ufc_df.dropna(how='all')\n",
    "ufc_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015913d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after cleaning, down to 265 observations\n",
    "\n",
    "ufc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae91a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I see that the twitter links are now contained within lists. Lets fix it.\n",
    "\n",
    "print(type(ufc_df.loc[0, 3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fafd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_df[3] = ufc_df[3].str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d87ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_df\n",
    "# now without the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c5366a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets rename the columns: \n",
    "ufc_df.columns = ['name', 'nickname', 'weight_class', 'twitter', 'ufc_profile']\n",
    "ufc_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae1e23f",
   "metadata": {},
   "source": [
    "### So far so good.\n",
    "\n",
    "Now I have some different variables in my dataframe- but mostly just categoricals and links. \n",
    "The weightclass variable will constitute my non-binary categorical variable. \n",
    "But we need some more. Lets first create a binary variable - the most obvious one being a sex variable. I see that the fighters are not filtered by sex. However, we can easily do this by spotting how the weightclasses are seperated. For women, they are all called \"women's X-weight\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de8d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see how many women we have:\n",
    "\n",
    "ufc_df.weight_class.str.count(\"Women\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c92d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the sex variable\n",
    "\n",
    "ufc_df['gender'] = np.where(ufc_df.weight_class.str.count(\"Women\"), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8840fed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# women are now 0 and men are 1\n",
    "\n",
    "ufc_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077987a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the 1 and 0 in the gender column to make sure we get the same results as when counting the \"women\"\n",
    "# string from the weight class\n",
    "\n",
    "ufc_df['gender'].value_counts()\n",
    "\n",
    "# and it matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40c75c2",
   "metadata": {},
   "source": [
    "___ \n",
    "\n",
    "#### Scraping information from each fighter profile\n",
    "\n",
    "As there are lots of information and stats on each of the fighter's profile, we can scrape this information and add it to the dataframe. \n",
    "\n",
    "The performance information we want from the profiles are: \n",
    "\n",
    "* wins by knockout (continuous) \n",
    "* wins by submission (continuous) \n",
    "* striking accuracy (stated in percentage on website but divided by 100 here) (continuous)\n",
    "* significant strikes landed per min (continuous)\n",
    "* Average fighting time (continuous)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4bcfdf",
   "metadata": {},
   "source": [
    "___ \n",
    "First: **number of wins by knockout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302a96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knockout = []\n",
    "\n",
    "from tqdm.notebook import tqdm # using tqdm to get a feeling of the progress of the code\n",
    "\n",
    "\n",
    "for link in tqdm(ufc_df['ufc_profile']):\n",
    "    try:\n",
    "        url1 = rq.get(link)\n",
    "        soup_temp = BeautifulSoup(url1.text)\n",
    "        knockout_temp = soup_temp.find(\"p\", class_= \"athlete-stats__text athlete-stats__stat-numb\").text\n",
    "        knockout.append(knockout_temp)\n",
    "    except:\n",
    "        knockout.append(np.nan)\n",
    "        \n",
    "# not all fighters have 1) won by knockout or 2) have the information listed. In those cases, they get NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d1a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knockout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc3c665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ufc_df['wins_knockout'] = knockout \n",
    "ufc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386c9fa",
   "metadata": {},
   "source": [
    "___ \n",
    "\n",
    "Next: **wins by submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca86696",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission = []\n",
    "\n",
    "for link in tqdm(ufc_df['ufc_profile']):\n",
    "    try:\n",
    "        url1 = rq.get(link)\n",
    "        soup_temp = BeautifulSoup(url1.text)\n",
    "        submission_temp = soup_temp.find_all(\"p\", class_= \"athlete-stats__text athlete-stats__stat-numb\")[1].text\n",
    "        submission.append(submission_temp)\n",
    "    except IndexError:\n",
    "        submission.append(np.nan)\n",
    "\n",
    "# not all fighters have 1) won by submission or 2) have the information listed. In those cases, they get NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94afb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffbfdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_df['wins_submission'] = submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63040591",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5302acce",
   "metadata": {},
   "source": [
    "___ \n",
    "\n",
    "Next: **striking accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "striking_accuracy = []\n",
    "\n",
    "\n",
    "for link in tqdm(ufc_df['ufc_profile']):\n",
    "    try:\n",
    "        url1 = rq.get(link)\n",
    "        soup_temp = BeautifulSoup(url1.text)\n",
    "        temp1 = soup_temp.find(\"svg\", class_= \"e-chart-circle\").text\n",
    "        temp2 = re.sub(r'\\D', '' , temp1.strip()) # temp1 contains text. We are only interested in the number\n",
    "        temp3 = int(str(temp2)[:2])/100 # the number is posted twice. We only want it once and it is a 2 \n",
    "                                        # digit number + divide by 100 as it is stated in percentage\n",
    "        striking_accuracy.append(temp3)\n",
    "    except:\n",
    "        striking_accuracy.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b8bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "striking_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cfc955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding it to df\n",
    "\n",
    "ufc_df['striking_accuracy'] = striking_accuracy \n",
    "ufc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b8509b",
   "metadata": {},
   "source": [
    "___ \n",
    "\n",
    "Next: **significant strikes landed per min**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816ff992",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "str_landed_min = []\n",
    "\n",
    "for link in tqdm(ufc_df['ufc_profile']):\n",
    "    try:\n",
    "        url1 = rq.get(link)\n",
    "        soup_temp = BeautifulSoup(url1.text)\n",
    "        temp1 = soup_temp.find(\"div\", class_= \"c-stat-compare__number\").text\n",
    "        temp2 = re.sub(r'\\n', '' , temp1.strip()) # temp1 contains \\n. We are only interested in the number\n",
    "        str_landed_min.append(temp2)\n",
    "    except:\n",
    "        str_landed_min.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f33484",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_landed_min\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99bbca",
   "metadata": {},
   "source": [
    "For three of the fighters, the extraction was wrong, resulting in a value of 00:00. \n",
    "Looking into the profile webpages for the fighters manually, it turns out that the websites contain no values as they are not updated with fighter info. \n",
    "\n",
    "I will manually correct for these below after having included the list to the df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6539413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the list to the df.\n",
    "\n",
    "ufc_df['sig_str_landed_min'] = str_landed_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1172477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting values for fighter index 17, 71 and 157\n",
    "\n",
    "ufc_df['sig_str_landed_min'][17] = np.nan\n",
    "ufc_df['sig_str_landed_min'][71] = np.nan\n",
    "ufc_df['sig_str_landed_min'][157] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d583e01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ufc_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e6c579",
   "metadata": {},
   "source": [
    "___ \n",
    "\n",
    "Next: **average fight time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532247d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_fight_time = []\n",
    "\n",
    "for link in tqdm(ufc_df['ufc_profile']):\n",
    "    try:\n",
    "        url1 = rq.get(link)\n",
    "        soup_temp = BeautifulSoup(url1.text)\n",
    "        temp1 = soup_temp.find_all(\"div\", class_= \"c-stat-compare__number\")[7].text\n",
    "        temp2 = re.sub(r'\\D', '', temp1.strip())\n",
    "        temp3 = int(str(temp2))/100\n",
    "        avg_fight_time.append(temp3)\n",
    "    except:\n",
    "        avg_fight_time.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999dec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fight_time\n",
    "\n",
    "# some of the fighter get nan value here as the website is not updated with the average fighting time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa158a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ufc_df['avg_fight_time'] = avg_fight_time\n",
    "ufc_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77180be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max(avg_fight_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e718910",
   "metadata": {},
   "source": [
    "I was initially very confused regarding the fight time statistics for certain fighters. Specifically, I observed that some fighters had an average fight time that exceeded the standard duration of 15 minutes (as fights consists of three rounds, each of five minutes). While this discrepancy initially puzzled me, I eventually discovered that it was likely due to the inclusion of overtime periods or other factors.\n",
    "\n",
    "When manually examining fighters with an average fight time exceeding 15 minutes, I found that the information had been accurately extracted from the website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef187ca5",
   "metadata": {},
   "source": [
    "___ \n",
    "\n",
    "Now I will move on from the fighter stats and extract some background info on the fighters.\n",
    "More specifically, I will extract the following background information: \n",
    "* status\n",
    "* age \n",
    "* reach "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f6d109",
   "metadata": {},
   "source": [
    "___ \n",
    "\n",
    "\n",
    "First: fighter status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = []\n",
    "\n",
    "# some of the fighters dont have fighter status and the code instead extracted the fighters hometown/country.\n",
    "# These had the format \"hometown, country\" and i thus had to tell the code that if there was a comma in the \n",
    "# text, make this a nan value instead. \n",
    "\n",
    "string = ','\n",
    "\n",
    "for link in tqdm(ufc_df['ufc_profile']):\n",
    "        url1 = rq.get(link)\n",
    "        soup_temp = BeautifulSoup(url1.text)\n",
    "        temp1 = soup_temp.find(\"div\", class_= \"c-bio__text\").text\n",
    "        if string not in temp1: \n",
    "            status.append(temp1)\n",
    "        else:\n",
    "            status.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1b6dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce36f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_df['status'] = status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b34d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a binary variable of status. \n",
    "# with this code, the default will be fighting =0 and the \"not fighting for various reasons (not fighting/ \n",
    "# retired/ nan/ etc.) = 1. \n",
    "\n",
    "ufc_df['status_binary'] = np.where(ufc_df.status.str.count(\"Active\"), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e1daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a885ec",
   "metadata": {},
   "source": [
    "___ \n",
    "\n",
    "\n",
    "Next: **age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca8223",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = []\n",
    "\n",
    "\n",
    "for link in tqdm(ufc_df['ufc_profile']):\n",
    "        url1 = rq.get(link)\n",
    "        soup_temp = BeautifulSoup(url1.text)\n",
    "        temp1 = soup_temp.find(\"div\", class_= \"field field--name-age field--type-integer field--label-hidden field__item\").text\n",
    "        age.append(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_df['age']= age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9079bb54",
   "metadata": {},
   "source": [
    "___ \n",
    "\n",
    "\n",
    "Next: **reach**\n",
    "\n",
    "Not all fighters had their reach info written on their page. \n",
    "In these situations, the -2 index would instead contain info on the fighters' debut date. \n",
    "Debut date consist of a string with more than 5 characters (e.g. JUL. 30, 2022). \n",
    "I thus coded that for each time the fighters -2 index would be a string with 5 characters or less, append it to the list. Otherwise, insert nan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be22eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reach = []\n",
    "\n",
    "\n",
    "for link in tqdm(ufc_df['ufc_profile']):\n",
    "        url1 = rq.get(link)\n",
    "        soup_temp = BeautifulSoup(url1.text)\n",
    "        temp1 = soup_temp.find_all(\"div\", class_= \"c-bio__text\")[-2].text\n",
    "        if len(temp1) <= 5:\n",
    "            reach.append(temp1)\n",
    "        else: \n",
    "            reach.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52788439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fac915",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_df['reach']= reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a01e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ufc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_df.to_csv('ufc_data.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf4756e",
   "metadata": {},
   "source": [
    "___ \n",
    "\n",
    "In retrospect, creating a function to get all the information might have been easier. But on the other hand, the web pages were different from fighter to fighter, and I think it would have caused more problems if I didn't go through the information bit by bit. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "___ \n",
    "\n",
    "## Section 2:  getting Twitter information \n",
    "\n",
    "To retrieve the Twitter information for each fighter, I used the column in the ufc_df that contained their respective Twitter links ('twitter'). Using the Twitter API, I extracted information such as follower count, total number of tweets, and their past 0-10 tweets. This information was subsequently stored in the twitter_df.\n",
    "\n",
    "After retrieving this information, I conducted several wordcounts as prescribed by the exam requirements:\n",
    "* a word count that's relevant to each observation in my DataFrames. \n",
    "* a word count where I find the most popular word in my text variable containing all fighters' tweets. \n",
    "    * Then I count how many times this popular word is used within each observation's tweets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c86cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tweeting and getting the different tokens from my AppCred file:\n",
    "\n",
    "import tweepy\n",
    "\n",
    "from AppCred_Template import BEARER_TOKEN\n",
    "from AppCred_Template import CONSUMER_KEY, CONSUMER_SECRET\n",
    "from AppCred_Template import ACCESS_TOKEN, ACCESS_TOKEN_SECRET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the api\n",
    "\n",
    "api = tweepy.Client(bearer_token = BEARER_TOKEN,\n",
    "                       consumer_key = CONSUMER_KEY,\n",
    "                       consumer_secret = CONSUMER_SECRET,\n",
    "                       access_token = ACCESS_TOKEN,\n",
    "                       access_token_secret = ACCESS_TOKEN_SECRET,\n",
    "                       return_type=dict,        # Return the response as a Python dictionary.\n",
    "                       wait_on_rate_limit=True) # Wait once the rate limit is reached. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b6dc57",
   "metadata": {},
   "source": [
    "Right now, the twitter links contain the entire link in the dataframe. Not just the handle. Below, I will make a list only consisting of the twitter handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_df['twitter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c954d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using regex to only get the twitter handle\n",
    "\n",
    "import re\n",
    "\n",
    "twitter_handle = []\n",
    "\n",
    "for string in ufc_df['twitter']: \n",
    "    temp_string = re.sub(r'^\\w\\w\\w\\w\\w\\W\\W\\W\\w\\w\\w\\w\\w\\w\\w\\W\\w\\w\\w\\W', '', str(string))\n",
    "    twitter_handle.append(temp_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31151ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_handle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be1c97",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "To get hold of various twitter information on the fighters' twitter profiles, i will look into the user field of public metrics. This contains, among other, information on followers count, following count and number of tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898375d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object containing everything so i wont have to ask twitter for each item and wait:\n",
    "\n",
    "twitter_info = []\n",
    "\n",
    "for handle in twitter_handle:   \n",
    "    try:\n",
    "        if len(handle) <= 3: \n",
    "            twitter_info.append(np.nan) \n",
    "        else: \n",
    "            handle_temp = api.get_user(username= handle, user_fields = ['public_metrics'])\n",
    "            twitter_info.append(handle_temp)\n",
    "    except: \n",
    "        twitter_info.append(np.nan)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0f5818",
   "metadata": {},
   "source": [
    "I included the 'if statement' in this code, as the fighters with no twitter handle had the handle string 'nan' and not a NaN. This resulted in that a person on twitter with a twitter handle of 'nan' was included several times - and he had no connection to the ufc whatsoever. As a result, I had to change this, saying that if the twitter handle was equal to or below 3, let this be NaN. \n",
    "From eyeballing the list above, no other fighter has a twitter handle at 3 characters or less. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ee8dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea2b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(twitter_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d971b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(twitter_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fca0a92",
   "metadata": {},
   "source": [
    "**Extracting the number of followers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15511dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "follower_count = []\n",
    "\n",
    "for i in range(len(twitter_info)):\n",
    "    try:\n",
    "        follower_count_temp = twitter_info[i]['data']['public_metrics']['followers_count']\n",
    "        follower_count.append(follower_count_temp)\n",
    "    except: \n",
    "        follower_count.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64d9672",
   "metadata": {},
   "outputs": [],
   "source": [
    "follower_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e312c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(follower_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a71f9",
   "metadata": {},
   "source": [
    "**Extracting how many profiles each fighter is following:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0384e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "following_count = []\n",
    "\n",
    "for i in range(len(twitter_info)):\n",
    "    try:\n",
    "        following_count_temp = twitter_info[i]['data']['public_metrics']['following_count']\n",
    "        following_count.append(following_count_temp)\n",
    "    except: \n",
    "        following_count.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c4e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "following_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a59295",
   "metadata": {},
   "source": [
    "**Extracting the total tweet count of each fighter:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_count = []\n",
    "\n",
    "for i in range(len(twitter_info)):\n",
    "    try:\n",
    "        tweet_count_temp = twitter_info[i]['data']['public_metrics']['tweet_count']\n",
    "        tweet_count.append(tweet_count_temp)\n",
    "    except: \n",
    "        tweet_count.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e875ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeed7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the extracted information in a dataframe\n",
    "\n",
    "twitter_df = pd.DataFrame(list(zip(twitter_handle, follower_count, following_count, tweet_count)),\n",
    "               columns =['twitter_handle', 'follower_count', 'following_count', 'tweet_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87624247",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df\n",
    "\n",
    "# As visible below, I am keeping the rows for fighters that do not have twitter, resulting in NaNs in the \n",
    "# twitter rows, as I am planning on merging the UFC and twitter datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e366f41",
   "metadata": {},
   "source": [
    "**Extracting the tweets:**\n",
    "\n",
    "Twitter is a central way of communicating in the UFC sport, and it makes sense that many UFC fighters invest much time and produce many tweets. \n",
    "However, due to my first-level developer account, there are certain limitations to how many tweets I can get hold of and how many days back I can access them. \n",
    "Given that I also have more than 200 fighters in my dataset, I assume it is acceptable not to extract all tweets for each fighter (as we can see on the tweet_count, Twitter is heavily used) but that it is adequate only to obtain 1-10 tweets per fighter. \n",
    "\n",
    "I will do this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bbcb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object containing the timeline for the fighters. \n",
    "\n",
    "fighter_timeline = []\n",
    "\n",
    "for i in range(len(twitter_info)):\n",
    "    try:\n",
    "        id_temp = twitter_info[i]['data']['id']\n",
    "        timeline_temp = api.get_users_tweets(id_temp)\n",
    "        fighter_timeline.append(timeline_temp)\n",
    "    except: \n",
    "        fighter_timeline.append(np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be90968",
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b45bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fighter_timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814e84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a feeling of how the data is structured\n",
    "fighter_timeline[0]['data'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f3f84d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for fighter in fighter_timeline: \n",
    "    try: \n",
    "        print(len(fighter['data']))\n",
    "    except TypeError: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aafb379",
   "metadata": {},
   "source": [
    "I see that we maximum get 10 tweets per fighter. I assume those with a smaller tweet number simply produced fewer tweets within the past 7 days. \n",
    "\n",
    "Within the fighter_timeline, there are many fighters, each with a dict of data and herunder, 0-10 strings. \n",
    "I have extracted these by using two for loops:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c2027",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweets_text1 = []\n",
    "\n",
    "for fighter in fighter_timeline: \n",
    "    tweets_text = []\n",
    "    try: \n",
    "        for text in range(len(fighter['data'])):\n",
    "            text_temp = str(fighter['data'][text]['text'])\n",
    "            #print(text_temp)\n",
    "            tweets_text.append(text_temp)\n",
    "    except: \n",
    "        tweets_text.append(np.nan)\n",
    "    tweets_text1.append(tweets_text)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ee12fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_text1 now have the tweets divided seperated for each fighter. \n",
    "tweets_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweets_text1) # and we still have the NaNs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98377c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding it to the dataframe\n",
    "twitter_df['tweets_text'] = tweets_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa159d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f26634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking that everything is still there even though it is now in pandas dataframe\n",
    "twitter_df['tweets_text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c3bc8",
   "metadata": {},
   "source": [
    "**Next step: Conduct a word count relevant to each observation in my Twitter data frame** \n",
    "\n",
    "As fighters use Twitter to comment on fights and fighters, both in real-time and between fighting events, I imagine a lot of references to the UFC. I will count the word for each fighters' tweets and include it in the data frame.\n",
    "\n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8800afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting the first element of the list that we added to the dataframe\n",
    "\n",
    "tweets_text1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just trying with one of the fighter tweets before moving on to iterating through all of them\n",
    "count = 0\n",
    "\n",
    "for tweets in tweets_text1[1]:\n",
    "    if 'UFC' in tweets:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5687baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over the tweets to count how many times each fighter mentions UFC in their past tweets\n",
    "\n",
    "total_count = []\n",
    "count = 0\n",
    "\n",
    "for fighter in tweets_text1: \n",
    "    for tweets in fighter: \n",
    "        if tweets is np.nan: \n",
    "            pass \n",
    "                \n",
    "        elif 'UFC' in tweets:\n",
    "            count += 1\n",
    "    total_count.append(count)\n",
    "    count= 0 # need to state this again to \"restart\" the count object so it does not sum everything. \n",
    "            \n",
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90793bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53eaca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_df['ufc_count']= total_count\n",
    "twitter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6da4c8",
   "metadata": {},
   "source": [
    "\n",
    "___\n",
    "\n",
    "**Next step: More wordcounts**\n",
    "\n",
    "As mentioned above, I will conduct the following steps below: \n",
    "\n",
    "1. finding the most popular word in the text variable in your DataFrame. This will be the tweets_text variable. \n",
    "\n",
    "2. Afterwards, I will create a new variable that indicates the number of times that word is used for each observation in the data. \n",
    "\n",
    "\n",
    "#### Step 1: finding the most popular word in the whole text variable: tweets_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff17370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the object. It is exactly equal to the column in the dataframe (see above). \n",
    "# I simply find it easier to work with in this list form, but it is the same. \n",
    "\n",
    "tweets_text1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7c399d",
   "metadata": {},
   "source": [
    "To get the most popular word in the whole text variable, I find it difficult when the lists are nested. \n",
    "Below, I make a function that takes all the lists and flattens them so that I will get one long list only with strings of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95491bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def flatten(input_list):\n",
    "    output_list = []\n",
    "    for element in input_list:\n",
    "        if type(element) == list:\n",
    "            output_list.extend(flatten(element))\n",
    "        else:\n",
    "            output_list.append(element)\n",
    "    return output_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f7f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# like this\n",
    "\n",
    "tweets_text2 = flatten(tweets_text1)\n",
    "tweets_text2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d74a7c",
   "metadata": {},
   "source": [
    "Next step is to split the strings into seperate words. However, I get an error as I have NaNs in my list, \n",
    "And I cannot split an element that is not a string. Thus, I have to remove the NaNs. I do this by \n",
    "iterating over the elements in my list and assessing whether they are floats. When it encounters a float, \n",
    "it will move on; when its not a float, it will append this word to a list. \n",
    "My new list with strings, containing no floats, are thus within the res object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = []\n",
    "for element in tweets_text2:\n",
    "    try:\n",
    "        float(element)\n",
    "    except ValueError:\n",
    "        res.append(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4198f1fa",
   "metadata": {},
   "source": [
    "Now it is possible for me to split it. Furthermore, I will make all letters into lower case so that if a word has been written multiple times and only differs in upper/lower case, it will count the same. \n",
    "I do this by using list comprehension: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360db227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweets_text3 = [word for line in res for word in line.lower().split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ffd3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_text3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe64c4e",
   "metadata": {},
   "source": [
    "Before finding the most popular word, I will remove stopwords by using a stop_words file I have been introduced to at my university. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the file\n",
    "\n",
    "with open('stop_words.txt', 'r') as txt:\n",
    "    stop_words = txt.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd0ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the file by closing it \n",
    "txt.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807aff7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stop_words is a bit messy. Just cleaning it a bit below: \n",
    "\n",
    "stop_words\n",
    "\n",
    "stop_words_list = stop_words.replace('\\n', ' ').split(' ') \n",
    "# code to replace \\n with ' ' and split it at the ' '\n",
    "\n",
    "print(stop_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38091d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing non-word characters from the text \n",
    "\n",
    "tweets_words_only = [re.sub(r'\\W','',element).strip() for element in tweets_text3]\n",
    "tweets_words_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d2533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating over the words in the list to see if the words are present within the stop_words list. \n",
    "# if they are, they are passed. Otherwise, the are appended to the list relevant_words. \n",
    "\n",
    "relevant_words = []\n",
    "\n",
    "for word in tweets_words_only: \n",
    "    if word in stop_words: \n",
    "        pass\n",
    "    else: \n",
    "        relevant_words.append(word)\n",
    "        \n",
    "relevant_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efcb082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND now we can get the frequency of the most used word in the whole text variable. \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "frequent_words = Counter(relevant_words)\n",
    "top_four = frequent_words.most_common(4)\n",
    "print(top_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8fee88",
   "metadata": {},
   "source": [
    "I believe I picked out a very reasonable word in my first word count, mirrored in the word count of the entire text variable, as shown here. UFC is the most frequently used word among fighters' tweets. As I wrote above, I believe this makes sense as Twitter is heavily used within the organisation and community. \n",
    "As step two of this exam project is to create a new variable that indicates the number of times that this most popular word is used for each observation in the data, I have already created this above. To ensure that I fulfil the exam requirements, I will create a new variable that indicates the number of times the second most used word is mentioned in each fighter's tweets, that being \"fight\". I will do this below.\n",
    "\n",
    "___\n",
    "\n",
    "#### Step 2: Create a new variable that indicates the number of times the *second* most frequent word is used for each observation in the data (as I accidentally already counted the most frequent word and added this to the data frame)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03eb2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same code as above with the 'UFC' string within each fighters' tweets. \n",
    "# Iterating over the tweets to count how many times each fighter mentions fight in their tweets\n",
    "\n",
    "total_count1 = []\n",
    "count1 = 0\n",
    "\n",
    "for fighter in tweets_text1: \n",
    "    for tweets in fighter: \n",
    "        if tweets is np.nan: \n",
    "            pass # same here as above with the first 'UFC' count. \n",
    "                \n",
    "        elif 'fight' in tweets:\n",
    "            count1 += 1\n",
    "    total_count1.append(count1)\n",
    "    count1= 0 # need to state this again to \"restart\" the count object so it does not sum everything. \n",
    "            \n",
    "total_count1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe80184",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter_df['fight_count']= total_count1\n",
    "twitter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a73756",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "___ \n",
    "\n",
    "## Section 3: Merging datasets\n",
    "\n",
    "\n",
    "I have tried to construct these two data frames so that I could merge them in this step. That is, I have kept those NANs in my head in every task, ensuring that even though fighters' might not have Twitter or may not have all background information, I have kept the observation. \n",
    "When conducting the analysis later, I intend to create copies of the data frames and remove the fighters with NANs in key variables for my given analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ccfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the index of the ufc dataframe was not reset after having removed observations, it messed with the \n",
    "# concenation below. Thus, I have reset them here and used drop=True as to not add the \"old\" index as a column\n",
    "ufc_df = ufc_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24119cb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_df = pd.concat([ufc_df, twitter_df], axis = 1) # axis=1 for horizontal join\n",
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d1333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of the columns \n",
    "\n",
    "for col in total_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb5e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting an overview of how many variables are nummeric\n",
    "\n",
    "numerics = total_df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "print(range(len(numerics))) # there is 9 and their names are as below\n",
    "numerics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95882e5f",
   "metadata": {},
   "source": [
    "I see that the 'wins by submission', 'wins by knockout', 'significant strikes landed per min' and ' reach' is not nummeric. Will change this below.\n",
    "\n",
    "___ \n",
    "\n",
    "When trying to convert the values within these variables to integer, I get an error as it will not accept the NaNs in the dataframe. I thought about whether I wanted to make a copy of the dataframe and remove rows with NANs when each variable was needed or whether I simply filled the NaNs with zero. In these instances I fill them with 0, as not all fighters' have (yet) won by submission or knockout. These got NaN as the UFC website did not post the metric if they had not won. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb3ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['wins_knockout'] = total_df['wins_knockout'].fillna(0).astype('int')\n",
    "total_df['wins_submission'] = total_df['wins_submission'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa00f2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ce09c",
   "metadata": {},
   "source": [
    "For striking accuracy, however, I am certain the fighters do not have an accuracy of 0. For fighters with NaN as striking accuracy, it may instead be that the webpage was not updated. Let me count how many fighters it is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57494f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_df['striking_accuracy'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0008634",
   "metadata": {},
   "source": [
    "As it is only three fighters, I will remove these from the dataframe for simplicity reasons. It might be more proper to make copies of the total_df dataset and only remove these observations when the variables are needed for analysis, thus, keeping them in the total dataframe and using the other variables of these observations in other analyses. \n",
    "\n",
    "However, for both this variable and 'reach' below, I evaluated that a total loss of 9 observations is \n",
    "not too many. Nevertheless, I recognise the ideal way of doing this might be to make new dataframes for each variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing them\n",
    "total_df = total_df.dropna(subset=['striking_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if they are removed. \n",
    "print(total_df['striking_accuracy'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e4f5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the rows were dropped from the whole dataset\n",
    "# from 265 to 262 are three --> they are removed. \n",
    "total_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35743eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the striking_accuracy into integer as well: \n",
    "\n",
    "total_df['striking_accuracy'] = total_df['striking_accuracy'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6a7998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing with reach as with striking accuracy:\n",
    "\n",
    "print(total_df['reach'].isna().sum())\n",
    "\n",
    "# there are six rows with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d96925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing these\n",
    "total_df = total_df.dropna(subset=['reach'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f955c",
   "metadata": {},
   "source": [
    "As I need the variable as integers, and the values at the moments are of 80.00, 65.00, etc. - character, I have to loop through each row, first converting each value to floats and afterwards converting them to integers. I save these in a new list and substitute the old reach column with this new list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65711dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_reach = []\n",
    "\n",
    "for row in total_df['reach']: \n",
    "    val = float(row)\n",
    "    new_reach.append(int(val))\n",
    "    \n",
    "new_reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034bbdc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# substituting old reach column with new\n",
    "total_df['reach'] = new_reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f5f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final control of whether the variables really are nummeric now: \n",
    "\n",
    "numerics = total_df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "print(range(len(numerics))) \n",
    "numerics\n",
    "\n",
    "# and they are here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573a941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving total_df as csv file\n",
    "\n",
    "total_df.to_csv('total_df_ufc_twitter.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaae428",
   "metadata": {},
   "source": [
    "Now the data frames are merged into one, total_df, and the different variables that should be numeric are converted. \n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "## Section 4: Data visualization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e45d0b",
   "metadata": {},
   "source": [
    "As the task here, among others, is to plot the outcome variables, I will briefly just expand on the outcome variables I have in mind. \n",
    "\n",
    "For the linear regression, I thought it interesting to investigate wins by knockout as a function of reach - I don't know much about fighting, so I might disregard some techniques here, but I find it reasonable to investigate whether arm length have an effect on number of knockouts.\n",
    "\n",
    "For the logistic regression, I intend to explore the fighters' fighting status as a function of number of wins - that is, I will make a new column in the dataset just below where I aggregate the values within the two columns wins_knockout and wins_submission. \n",
    "\n",
    "Below, I will 1) plot the outcome variables of \"wins_knockout\" and \"status_binary\" on their own below. I will do this by using histograms which are relevant for continuous and/or discrete data and is useful in visualising the distribution of the data.\n",
    "\n",
    "Afterwards, I will 2) make two bivariate plots containing the outcome variable and two predictors \n",
    "(one predictor per plot). \n",
    "\n",
    "#### 1. plotting the outcome variables on their own\n",
    "\n",
    "#### Visualizing \"wins_knockout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b96508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "     \n",
    "plt.hist(total_df['wins_knockout'], ec=\"k\") #ec=\"k\" draws the lines between each bin. \n",
    "\n",
    "# adding title and labels\n",
    "plt.title(\"Frequency of wins by knockout by UFC fighters\")\n",
    "plt.xlabel(\"Number of knockout wins\")\n",
    "plt.ylabel(\"Count of knockout wins\")\n",
    "\n",
    "plt.show()# to avoid clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d575c6a",
   "metadata": {},
   "source": [
    "As depicted in the plot, there are a few exceptional fighters with a significantly high number of wins by knockout, although they represent a minority. This plot is a good overview the range of knockout wins and the number of fighters falling within that range but it does not give us a good sense of the distribution at the lower end (or from 0-10/11). To obtain a more fine grained impression, we could consider excluding these outliers, but for now, this plot suffices in presenting an overall view of the distribution.\n",
    "\n",
    "#### Visualizing status_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5906e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(total_df['status_binary'], bins=[-.5,.5,1.5], ec=\"k\")\n",
    "\n",
    "# adding title and labels\n",
    "plt.title(\"UFC Fighting status frequency\")\n",
    "plt.xlabel(\"Fighting status: 0=active, 1=non-active\")\n",
    "plt.ylabel(\"Count fighting status among fighters\")\n",
    "plt.xticks((0,1))\n",
    "\n",
    "plt.show()# to avoid clutter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d066c0",
   "metadata": {},
   "source": [
    "As explicitly stated in the x-axis of the figure, a default value of 0 corresponds to \"fighting\" and a value of 1 represents \"not fighting.\" The majority of the fighters listed on the website are currently active, participating in UFC fights, and engaged in the sport. However, there are also some non-active fighters featured on the website. The criteria for organizing this list and determining when to remove a non-active fighter is unknown. It is possible that UFC may choose to keep high-ranking non-active fighters on the website for a certain period of time, removing them only when they are no longer of interest to the public. This is purely speculative, however, and not based on any specific information.\n",
    "\n",
    "For now, we can see the distribution of active and non-active fighters in the data frame.\n",
    "\n",
    "#### 2. make two bivariate plots containing the outcome variable and two predictors  (one predictor per plot)\n",
    "\n",
    "##### First bivariate plot: relationship between wins by knockout and reach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e053d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(total_df['reach'],total_df['wins_knockout'], )\n",
    "# reach on the x axis (independent) and wins_knockout on the y axis (dependent)\n",
    "\n",
    "# adds titles\n",
    "plt.title(\"Relationsship between UFC fighters' reach and wins by knockout\")\n",
    "# adds x-axis label\n",
    "plt.xlabel(\"Reach in inches\")\n",
    "# adds y-axis label\n",
    "plt.ylabel(\"Number of knockout wins\")\n",
    "# add x-axis tick label\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7c3cfe",
   "metadata": {},
   "source": [
    "As the plot is self-contained with labels and titles, we can now interpret it. We can see an upwards trend, suggesting that there might be a relationship between the variables. However, much scatter indicates that if a relationship exists, it may be weak. \n",
    "\n",
    "##### Second bivariate plot: relationship between fighter status and number of wins \n",
    "\n",
    "As explained above, I will make a new variable, total_wins, which aggregates the values of the columns wins_knockout and wins_submission. This will be the independent variable. I do this before I move on to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b460b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['total_wins'] = total_df.apply(lambda row: row.wins_knockout +\n",
    "                                  (row.wins_submission), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c48bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c75492",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(total_df['total_wins'],total_df['status_binary'], )\n",
    "# total wins on the x axis (independent) and status on the y axis (dependent)\n",
    "\n",
    "# adds titles\n",
    "plt.title(\"binary bivariate relationsship between number of wins and fighting status\")\n",
    "# adds x-axis label\n",
    "plt.xlabel(\"number of a fighters' total wins\")\n",
    "# adds y-axis label\n",
    "plt.ylabel(\"Fighter status, 0=active, 1=non-active\")\n",
    "# add x-axis tick label\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1dee8e",
   "metadata": {},
   "source": [
    "As usual, it is difficult to extract much meaning from binary bivariate visualizations; all observations clutter at either 0 or 1, which makes sense given the variable's format. However, we might still be able to get a small sense of it. For example, we see that more fighters with a fighter status of non-active have a high number of wins. Intuitivally, this might make sense: if a fighter now is retired, she/he might have had a long career with many many fights throughout it, resulting in many wins. A younger/newly accepted ufc fighter might not have had as many fights yet and thus, not many wins. \n",
    "\n",
    "As is typical with binary bivariate visualizations, it can be challenging to derive substantial insights given that observations tend to cluster at either 0 or 1, in line with the variable's binary format. Nevertheless, we may still be able to get some insights from this plot. Notably, we observe that a few number of non-active fighters have a substantial number of wins. This observation aligns with our intuition, as retired fighters may have had lengthy careers with numerous fights, leading to a higher number of wins. In contrast, a younger or newly accepted UFC fighter may not have had as many fights yet and consequently may have fewer wins. On the other hand, active fighters appear to have a higher overall number of wins compared to the majority of non-active fighters. This observation suggests that fighters who do not often win may eventually stop participating at this level of fighting.\n",
    "____\n",
    "\n",
    "## Section 5: Data Analysis \n",
    "\n",
    "The section is divided into several analyses: \n",
    "\n",
    "1. Linear regression \n",
    "2. Linear regression - control (categorical)\n",
    "4. Logistic regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d8145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages needed for this section\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from stargazer.stargazer import Stargazer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ff0736",
   "metadata": {},
   "source": [
    "##### Linear regression \n",
    "\n",
    "As explained above, I want to conduct a linear regression model of the continuous outcome variable \"wins_knockout\" (wins by knockout) and the predictor variable \"reach\". \n",
    "\n",
    "I hypothesize a positive relationsship indicating wins by knockout to increase for each unit increase in reach. \n",
    "\n",
    "Thus, I want to conduct a linear regression model with the continuous \"wins_knockout $Y_i$ as outcome and \"reach\" $X_i$ as predictor. In other words, I assume that the wins_knockout $Y_i$ is a function of the following:\n",
    "\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i\n",
    "$$\n",
    "\n",
    "where the errors $\\epsilon_i$ are independent, normally distributed variables with $E(\\epsilon_i)=0$ and $SD(\\epsilon_i)=\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592201b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimating the model \n",
    "\n",
    "est_mod = ols('wins_knockout~reach', data=total_df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d6ac8",
   "metadata": {},
   "source": [
    "In the cell below, I print the estimates of the regression coefficients $\\beta_0$ and $\\beta_1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cde686",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_mod.params.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961b1a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding sd \n",
    "np.sqrt(est_mod.scale).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e9d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shown more clearly using stargazer\n",
    "\n",
    "s = Stargazer([est_mod])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c579a",
   "metadata": {},
   "source": [
    "We thus get the following estimated relationship between wins by knockout and reach:\n",
    "\n",
    "$$\n",
    "E(Y_i) = -16.79 + 0.32X_i + \\epsilon_i\n",
    "$$\n",
    "\n",
    "where $\\epsilon_i$ are independent, normally distributed with $E(\\epsilon_i)=0$ and $SD(\\epsilon_i)=4.12$. \n",
    "\n",
    "Based on the model, it is possible to interpret the coefficients as follows: \n",
    "* the $\\beta_0 $ acts as the 'intercept' or 'constant'. The value of $\\beta_0 $, being -16.79, is the value of the dependent variable, wins by knockout, if the effect of the independent variable, reach, is 0. This does not make much sense in this instance, as no fighter have a reach=0 and thus, no  wins by knockout at -16.79. If I had been smart before conducting this analysis, I would have standardized the values of the data frame so that 0 in reach would have been the reach mean of the fighters instead. This would make the intercept more meaningful. But as always, there is more clarity in hindsight. \n",
    "\n",
    "\n",
    "* the $\\beta_1 $ denotes the independent variable, reach. In this instance,  $\\beta_1 $ is equal to 0.32. Thus, for each unit increase in reach, wins by knockout will be affected positively with a 0.32 increase. \n",
    "\n",
    "As is visible from the stargazer table above, the coefficient, reach, is significant. We can get this understanding as we see that reach has three stars next to it, indicating a p-value of p<0.01. This means that there is a smaller probability than 0.01 of getting such an estimate for reach if the true effect were actually zero. This also means that I can confirm my hypothesis that there is a positive relationship between reach and wins by knockout. \n",
    "\n",
    "If I consider this logically, it may be the result of an underlying effect of the different fighters' weight classes - a variable that I have not controlled for in my analysis. All fighters are classified into weight classes, which ensures that no fighter has an unfair advantage if, for example, a larger fighter were up against a smaller fighter. In such cases, the techniques of the sport may not matter as much as the sheer physical size and strength of the fighter. For instance, a smaller fighter with a **shorter reach** may need to strike their opponent multiple times to secure a knockout, and in this instance, other techniques may be more effective in lighter weight classes. On the other hand, a heavyweight fighter with a **longer** reach may only need to strike their opponent once to secure a win by knockout. Therefore, it is possible that winning by knockout is more prevalent among higher weight classes and that weight class acts as a confounding factor. I will address this issue further below in the next section by controlling for weight class in my analysis.\n",
    "\n",
    "Returning to the model itself, this is the model that is based on the actual observed data. To assess the distribution's spread and the model's usefulness, I will employ simulation and visualization techniques. This approach will enable me to determine whether the model produces data that closely resembles the actual data in the total_df.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24db9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first plotting the estimated relationship between wins_knockout (Y) and reach (X):\n",
    "\n",
    "def est_exp_ko_win(x) : return -16.79 + 0.32*x\n",
    "\n",
    "sns.scatterplot(data=total_df,x='reach',y='wins_knockout')\n",
    "sns.lineplot(x=[total_df['reach'].min(),total_df['reach'].max()],\n",
    "             y=[est_exp_ko_win(total_df['reach'].min()),est_exp_ko_win(total_df['reach'].max())],\n",
    "             color='black',linewidth=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b372fa",
   "metadata": {},
   "source": [
    "The intercept is at -16.79 when reach has a value of 0. This means that the range of reach on the x-axis does not operate below approx. 55 and, thus, do not show the actual intercept. The plot indicates a positive relationship, but there is quite a bit of scatter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ac061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulating data\n",
    "\n",
    "def sim_lin_reg_mod(beta0, beta1, sigma, xs, col_names) :\n",
    "    ys = beta0 + beta1*xs + np.random.normal(0,sigma,xs.shape[0])\n",
    "    sim = pd.DataFrame(zip(xs,ys),columns=col_names)\n",
    "    return sim\n",
    "\n",
    "np.random.seed(0)\n",
    "ko_sims = [sim_lin_reg_mod(-16.79, 0.32, 4.12, total_df['reach'], ['reach','wins_knockout']) for i in range(0,5)]\n",
    "ko_sims[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the observed data and simulated\n",
    "\n",
    "dfs_plot = [total_df] + ko_sims\n",
    "\n",
    "min_y = pd.concat(dfs_plot)['wins_knockout'].min()\n",
    "max_y = pd.concat(dfs_plot)['wins_knockout'].max()\n",
    "\n",
    "fig,ax = plt.subplots(2,3,figsize=(14,8))\n",
    "\n",
    "for i in range(0,6) :\n",
    "    dat = dfs_plot[i]\n",
    "    a = ax.flatten()[i]\n",
    "    sns.scatterplot(data=dat,x='reach',y='wins_knockout',ax=a, alpha=0.70) # alpha denoting hue of observations\n",
    "    \n",
    "    sns.lineplot(x=[total_df['reach'].min(),total_df['reach'].max()],\n",
    "             y=[est_exp_ko_win(total_df['reach'].min()),est_exp_ko_win(total_df['reach'].max())],\n",
    "             color='black',linewidth=3,ax=a);\n",
    "    \n",
    "    if i==0 :\n",
    "        tit = 'Observed Outcomes'\n",
    "    else :\n",
    "        tit = 'Simulated Outcomes'\n",
    "    a.set(title=tit,ylim=[min_y-20,max_y+20])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2531ed4",
   "metadata": {},
   "source": [
    "In general, I believe that the estimated model generates data that looks similar to the actual data. However, there appears to be less variation in the *observed data* for fighters with a shorter reach compared to the *simulated outcomes* for fighters with a shorter reach. Additionally, it seems that there is more variation in the *observed data* for fighters with a longer reach compared to the *simulated outcomes* for fighters with a longer reach.\n",
    "\n",
    "This suggests that there may be an issue with the assumption that the standard deviation of the errors, $SD(\\epsilon_i)=\\sigma$, is the same for all $i$. This assumption restricts the standard deviation from being lower when reach is shorter and from being higher when reach is longer.\n",
    "\n",
    "\n",
    "Below, I will, among others, look into this problem by simulating and estimating the errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc0b0a7",
   "metadata": {},
   "source": [
    "__\n",
    "\n",
    "As I am interested in calculating the errors $\\epsilon_i$ according to the estimated model (where we assume these to be normally distributed), first step in doing do is to calculated the estimated $E(Y_i)$, that is, the outcome for each fighter - the wins by knockout for each fighter. \n",
    "\n",
    "I will do so as follows: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_estmod = total_df[['reach','wins_knockout']].copy()\n",
    "ko_estmod['exp_y'] = est_mod.predict() \n",
    "ko_estmod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b908c",
   "metadata": {},
   "source": [
    "As I have the estimated outcomes for each fighter, we can calculate the difference in estimated outcome for each fighter and actual observed outcome for each fighter. This difference between estmated and actual outcome for each fighter are the errors/residuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108ed64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_estmod['err'] = ko_estmod['wins_knockout'] - ko_estmod['exp_y']\n",
    "ko_estmod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d521985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that the estimated errors are calculated, we can visualize these errors against the estimated wins by \n",
    "# knockout (exp_y): \n",
    "\n",
    "\n",
    "ax = sns.scatterplot(data=ko_estmod, x='exp_y', y='err')\n",
    "ax.axhline(color='black',linestyle='--',linewidth=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a4eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making scatterplots of errors that are simulated according to the estimated model. \n",
    "# I am making 8 simulations (not for any specfic reason other than to see many simulations). \n",
    "\n",
    "np.random.seed(0)\n",
    "errs_sim = [np.random.normal(0, 4.12, 256) for i in range(0,8)] \n",
    "                            #0 for mean of errors according to the assumptions of the model\n",
    "                            # 4.12 for the standard deviation \n",
    "                            # 256 for n fighters in the dataset\n",
    "            \n",
    "errs_plot = [ko_estmod['err']] + errs_sim \n",
    "\n",
    "fig, ax = plt.subplots(3,3,figsize=(16,12))\n",
    "\n",
    "for i in range(0,9) :\n",
    "    errs = errs_plot[i]\n",
    "    a = ax.flatten()[i]\n",
    "    sns.scatterplot(x=ko_estmod['exp_y'],y=errs,ax=a)\n",
    "    a.axhline(color='black',linestyle='--',linewidth=3);\n",
    "    \n",
    "    if i==0 :\n",
    "        tit = 'Estimated Errors'\n",
    "    else :\n",
    "        tit = 'Simulated Errors'\n",
    "    a.set(title=tit,xlabel='exp_y',ylabel='err',ylim=[-25,25]) # setting the limitations of the y axis \n",
    "                                                               # so that it fits the data \n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3b372",
   "metadata": {},
   "source": [
    "By comparing the distribution of errors between the estimated errors and simulated errors, it is visible that they are not completely similar. The simulated errors exhibit greater similarity to one another, while the estimated errors display a larger spread as the expected value of y, i.e. the wins by knockout, increases.  As was suggested in my interpretation of the plots above, this may indicate that the assumption of constant standard deviation of errors (homoskedasticity) is violated. \n",
    "\n",
    "Aside from homoscedasticity, another key assumption of the linear regression model is normality. This can be assessed through a qq plot, which is presented below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3831860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "sm.qqplot(ko_estmod['err'],line='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa55e412",
   "metadata": {},
   "source": [
    "As the qqplot shows that all errors do not follow the red line, we cannot assume normally distributed errors and thus, the normality assumption is also violated. \n",
    "\n",
    "These violated assumptions of both normality of errors, and homoscedasticity hurt the reliability of the coefficients we found above. We thus have to estimate the coefficients again and change the model's assumptions. With the violated assumptions removed, we now have the following assumptions for the model: \n",
    "\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i\n",
    "$$\n",
    "\n",
    "where $\\epsilon_i$ are independent random variables (NOT independent, normally distributed) with  $E(\\epsilon_i)=0$ and $SD(\\epsilon_i)=\\sigma$. \n",
    "\n",
    "As the errors do not have the same standard deviation (they are heteroskedastic), we will estimate the coefficients using the robust 95% confidence intervals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a859e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_mod.get_robustcov_results(cov_type='HC3').summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c41d3e",
   "metadata": {},
   "source": [
    "The estimates ended up being the same as above. Thus, it should be mentioned that there might be a reliability issue with the coefficients. \n",
    "\n",
    "\n",
    "___ \n",
    "\n",
    "### Linear regression - controlling for weight classes\n",
    "\n",
    "As previously mentioned, I have a hypothesis that the estimated coefficient for reach is a result of an underlying effect of the different weight classes, and that weight class is the true explanatory factor for wins by knockout. To test this theory, I will run a linear regression model similar to the one above, but this time I will include weight class as a control variable. I intend not to remove weight classes based on sex.\n",
    "\n",
    "\n",
    "With wins by knockout as outcome (Yi) and the predictors of reach and weightclass and the same assumptions as  above, the model is written as follows: \n",
    "\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1 X_{i,1} + \\beta_2 X_{i,2} + \\beta_3 X_{i,3} + \\beta_4 X_{i,4}+ \\beta_5 X_{i,5}+ \\beta_6 X_{i,6} + \\beta_7 X_{i,7} + \\beta_8 X_{i,8} + \\beta_9 X_{i,9} + \\beta_10 X_{i,10}+ \\beta_11 X_{i,11}+  \\beta_ 12 X + \\epsilon_i\n",
    "$$\n",
    "\n",
    "where $\\epsilon_i$ are independent random variables with  $E(\\epsilon_i)=0$ and $SD(\\epsilon_i)=\\sigma$. \n",
    "\n",
    "Thus, the categorical values is written as follows depending on the weight class of interest: \n",
    "\n",
    "- $X_{i,1} = 1$ if $i$ indicate featherweight, else 0\n",
    "- $X_{i,2} = 1$ if $i$ indicate flyweight, else 0\n",
    "- $X_{i,3} = 1$ if $i$ indicate heavyweight, else 0\n",
    "- $X_{i,4} = 1$ if $i$ indicate heavyweight, else 0\n",
    "- $X_{i,5} = 1$ if $i$ indicate lightweight, else 0\n",
    "- $X_{i,6} = 1$ if $i$ indicate middleweight, else 0\n",
    "- $X_{i,7} = 1$ if $i$ indicate welterweight, else 0\n",
    "- $X_{i,8} = 1$ if $i$ indicate bantamweight, else 0\n",
    "- $X_{i,9} = 1$ if $i$ indicate featherweight, else 0\n",
    "- $X_{i,10} = 1$ if $i$ indicate flyweight, else 0\n",
    "- $X_{i,11} = 1$ if $i$ indicate strawweight, else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b045ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting how many weightclasses there are\n",
    "total_df['weight_class'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceabda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wanting the names of the different weight classes\n",
    "print(total_df['weight_class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6297ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using C() to dummy code the categorical variable weight class\n",
    "\n",
    "est_mod_2 = ols('wins_knockout~C(weight_class)+reach', data=total_df).fit() \n",
    "\n",
    "est_mod_2.get_robustcov_results(cov_type='HC3').summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53679cd0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "First, and for my own sake, I will just list the weightclasses from lowest to hight: \n",
    "\n",
    "* Strawweight (only womens strawweight in this dataset)\n",
    "* Flyweight\n",
    "* Bantamweight\n",
    "* Featherweight\n",
    "* Lightweight\n",
    "* Welterweight\n",
    "* Middleweight\n",
    "* Light Heavyweight\n",
    "* Heavyweight\n",
    "\n",
    "\n",
    "**Interpretation**: \n",
    "\n",
    "I could have chosen a continuous variable as my control or one with fewer categories, but given weightclass made logically sense to me to investigate, I will interpret the coeffiecients as follows, with focus on the control: \n",
    "* Intercept:The model predicts that fighters at bantamweight with a reach of 0 will have an estimated -2.3 wins by knockout. However, it is not possible for a fighter to have a reach of 0, and this value will become clearer once the arm length is added as a variable.\n",
    "\n",
    "\n",
    "* Reach: the model predicts that, holding weight classes constant, one unit increase in reach is associated with 0.13 more wins by knockout. \n",
    "\n",
    "\n",
    "* Betas : these shows the effect of going from one group to the other, starting from the intercept, assuming the reach variable is constant. That is, they denote the mean difference in wins by knockout between the different weight classes if reach were the same in each group. \n",
    "\n",
    "\n",
    "\n",
    "*reach*: Compared to the first model that only considered reach, wins by knockout increased by 0.32 for each unit increase in reach, where it only increases by 0.12 for each unit increase in reach in this model. Thus, its explanatory power has decreased and actually, is not significant anymore: As the CI for reach includes zero, I can conclude that reach is not statistically significant and that the reason for its signficance in the model above was its association with weight class. \n",
    "\n",
    "\n",
    "The dummy variable, i.e., the reference category is bantam weight. This means that when interested in estimating the average wins by knowckout for bantamweight with a reach of X, the outcome is simply $\\beta_0 + \\beta_(12) $. For other categories, it is the reference groups coefficient + the coefficient of the given weightgroup. This is also visible below.\n",
    "\n",
    "In all but the heaviest weight class, there is a negative relationsship between wins by knockout and weight class. This relationsship is most negative among light weightclasses and increases as the weight class increases. \n",
    "___\n",
    "\n",
    "For a fighter within the weight class of womens strawweight, the estimated average wins by knockout would be: \n",
    "\n",
    "\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1 * 1  + \\beta_2 *0 + \\beta_3 *0 + \\beta_4 *0 + \\beta_5 *0+ \\beta_6 *0 + \\beta_7 *0 + \\beta_8 *0 + \\beta_9 *0 + \\beta_10 *0+ \\beta_(11) *0+ \\beta_(12) + \\epsilon_i\n",
    "$$\n",
    "\n",
    "which, simplified (as all the other categorical variables are equal 0 when womens strawweight is equal 1), is:\n",
    "\n",
    "\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_(11) + \\beta_(12)\n",
    "$$\n",
    "\n",
    "\n",
    "That is:\n",
    "\n",
    "$$\n",
    "3.12 = -2.3 + -3.03 + 0.13*65 \n",
    "$$\n",
    "\n",
    "\n",
    "** x=65  is chosen here as the unit as I googled that the average UFC womens strawweight fighter has a reach of 65 inches. \n",
    "\n",
    "___\n",
    "\n",
    "For a fighter within the weight class of feather weight, the estimated average wins by knockout would be: \n",
    "\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1 *0 + \\beta_2 *0 + \\beta_3 *0 + \\beta_4 *0 + \\beta_5 *0+ \\beta_6 *0 + \\beta_7 *0 + \\beta_8 *0 + \\beta_9 *0 + \\beta_10 *0+ \\beta_(11) *1 + \\beta_(12) + \\epsilon_i\n",
    "$$\n",
    "\n",
    "which, simplified (as all the other categorical variables are equal 0 when featherweight is equal 1), is:\n",
    "\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1 + \\beta_(12)\n",
    "$$\n",
    "\n",
    "\n",
    "That is:\n",
    "\n",
    "$$\n",
    "5.02 = -2.3 + -1.78 + 0.13*70 \n",
    "$$\n",
    "\n",
    "** x=70 is chosen here as the unit as I googled that the average UFC featherweight fighter has a reach of 70 inches. \n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "For a fighter within the weight class of heavy weight, the estimated average wins by knockout would be: \n",
    "\n",
    "\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1 *0 + \\beta_2 *0 + \\beta_3 *1 + \\beta_4 *0 + \\beta_5 *0+ \\beta_6 *0 + \\beta_7 *0 + \\beta_8 *0 + \\beta_9 *0 + \\beta_10 *0+ \\beta_(11) *0+ + \\beta_(12) + \\epsilon_i\n",
    "$$\n",
    "\n",
    "which, simplified (as all the other categorical variables are equal 0 when featherweight is equal 1), is:\n",
    "\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_3 + \\beta_(12)\n",
    "$$\n",
    "\n",
    "\n",
    "That is:\n",
    "\n",
    "$$\n",
    "11.05 = -2.3 + 3.27 + 0.13*77.5 \n",
    "$$\n",
    "\n",
    "** x=77.5 is chosen here as the unit as I googled that the average UFC heavyweight fighter has a reach of 77.5 inches. \n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "##### BUT\n",
    "From the CI, it is also evident that not all weight classes are significant. \n",
    "\n",
    "I will present the coefficients and their p values more clearly with the stargazer table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0c06a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating estimated wins by knockout for womens strawweight\n",
    "\n",
    "-2.3 + -3.03 + 0.13*65 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f7f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating estimated wins by knockout for featherweight\n",
    "-2.3 + -1.78 + 0.13*70 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23223400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating estimated wins by knockout for heavyweight\n",
    "-2.3 + 3.27 + 0.13*77.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a28a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s_weight = Stargazer([est_mod_2])\n",
    "s_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e158488",
   "metadata": {},
   "source": [
    "The significance levels become clearer using stargazer. \n",
    "\n",
    "Only the weight classes of featherweight, heavyweight, and women's strawweight are significant. Above, I chose to interpret and calculate the outcomes only for the significant coefficients instead of for each and every coefficient, given that I have chosen a variable with many categories. \n",
    "\n",
    "Even though there are significant coefficients, it should be noted that the sample is small, and due to the many different weight classes, there are few observations within each. The results are thus not very reliable  and, thus, 1) may represent a different reflection of reality and 2) cannot be generalized to remaining UFC fighters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73efed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the different observations in each weight class \n",
    "\n",
    "total_df['weight_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98658f6e",
   "metadata": {},
   "source": [
    "### Logistic regression \n",
    "\n",
    "As explained in the beginning of the analysis section, I will conduct a logistic regression model of the binary outcome variable \"status_binary\" and the predictor variable \"total wins\". \n",
    "\n",
    "I hypothesize that there *is* a relationship and have two rather opposite theories: \n",
    "1. Each unit increase in number of wins is associated with increase in fighter status. This is derived from the thought that the more wins you have, the more it suggests a longer career, the more I rationalize the fighter to be retired now and thus, are not fighting. \n",
    "\n",
    "2. Each unit increase in number of wins is associated with decrease in fighter status. This is derived from the thought that if you, as a fighter, never win, you might be more likely to stop in the UFC as you dont have what it takes. So for each win, there is a decrease in fighter status towards 0=active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634bd41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining and fitting the model: \n",
    "\n",
    "log_reg = smf.logit(\"status_binary ~ total_wins\", data=total_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the confidence interval does overlap 0, so we can assume that the relationsship is not significant\n",
    "\n",
    "log_reg.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4988c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making it even more clear by running stargazer\n",
    "\n",
    "s1 = Stargazer([log_reg])\n",
    "s1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af88567",
   "metadata": {},
   "source": [
    "**Interpretation:** We cannot apply the same interpretation of linear regression to logistic regression because the function and relationship differ; The relationship in logistic regression follows a sigmoid curve, not a linear one. Thus, besides noting the lack of significance in the coefficients, we cannot say much else about them from the table. \n",
    "\n",
    "To derive interpretability from the logistic regression model, we can use predicted probabilities. This is demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01711c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fist sorting the values according to the total_wins variable so that the plot will look reasonable. \n",
    "# I change the indexes according to this new sorting as not to confuse myself below when the predicted\n",
    "# probabilities are listed next to the indexes. \n",
    "\n",
    "log_df = total_df.sort_values(\"total_wins\", ascending = False)\n",
    "log_df = log_df.reset_index(drop=True)\n",
    "log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This then lists the predicted probability for fighter status for each fighters' number of wins\n",
    "\n",
    "wins_predict = log_reg.predict(log_df['total_wins'])\n",
    "wins_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38737861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then the predicted probabilities for fighter status are plotted on the y axis and the number of wins \n",
    "# are on the x axis. This draws a better picture than 1) the first visualization of the binary variable above\n",
    "# and 2) the relationsship between the variables. \n",
    "\n",
    "sns.lineplot(data=log_df, x=\"total_wins\", y=wins_predict) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3fa43e",
   "metadata": {},
   "source": [
    "From this plot I can get see the predicted probabilities when everything else is held constant. Thus, I can interpret that the lower the total wins, the higher the probability of non-active fighter status. This also mean that the higher the total wins, the higher probability that the fighter is active. I cannot claim that this supports my second hypothesis, given the non-significant relationsship, but it looks as if the trend is leaning that way. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
